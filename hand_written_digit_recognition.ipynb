{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh9lWdaK5pSVNuf8M/29Lz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherryash100/HAND-WRITTEN-DIGIT-RECOGNITION/blob/main/hand_written_digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "6_W0RK8eKhDK",
        "outputId": "2b33a6ea-fa0f-434a-f13c-1feff326947c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST Dataset...\n",
            "✓ Dataset loaded!\n",
            "\n",
            "Training KNN Model...\n",
            "✓ KNN trained!\n",
            "\n",
            "Training SVM Model...\n",
            "✓ SVM trained!\n",
            "\n",
            "Training ANN Model...\n",
            "✓ ANN trained!\n",
            "\n",
            "======================================================================\n",
            "ALL MODELS READY!\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STARTING REAL-TIME RECOGNITION\n",
            "======================================================================\n",
            "\n",
            "Instructions:\n",
            "1. Show your index finger to the camera\n",
            "2. Draw digits (0-9) in the air\n",
            "3. Keep your finger visible while drawing\n",
            "4. Press 'C' to clear the canvas\n",
            "5. Click on video to stop\n",
            "\n",
            "Ready! Starting camera...\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        var video;\n",
              "        var div = null;\n",
              "        var stream;\n",
              "        var captureCanvas;\n",
              "        var imgElement;\n",
              "        var labelDiv;\n",
              "\n",
              "        var pendingResolve = null;\n",
              "        var shutdown = false;\n",
              "\n",
              "        function removeDom() {\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            video.remove();\n",
              "            div.remove();\n",
              "            video = null;\n",
              "            div = null;\n",
              "            stream = null;\n",
              "            imgElement = null;\n",
              "            captureCanvas = null;\n",
              "            labelDiv = null;\n",
              "        }\n",
              "\n",
              "        function onAnimationFrame() {\n",
              "            if (!shutdown) {\n",
              "                window.requestAnimationFrame(onAnimationFrame);\n",
              "            }\n",
              "            if (pendingResolve) {\n",
              "                var result = \"\";\n",
              "                if (!shutdown) {\n",
              "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "                    result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
              "                }\n",
              "                var lp = pendingResolve;\n",
              "                pendingResolve = null;\n",
              "                lp(result);\n",
              "            }\n",
              "        }\n",
              "\n",
              "        async function createDom() {\n",
              "            if (div !== null) {\n",
              "                return stream;\n",
              "            }\n",
              "\n",
              "            div = document.createElement('div');\n",
              "            div.style.border = '2px solid black';\n",
              "            div.style.padding = '10px';\n",
              "            div.style.width = '660px';\n",
              "            div.style.margin = '20px auto';\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            const modelDiv = document.createElement('div');\n",
              "            modelDiv.style.color = 'white';\n",
              "            modelDiv.style.fontSize = '18px';\n",
              "            modelDiv.style.padding = '10px';\n",
              "            modelDiv.style.marginBottom = '10px';\n",
              "            modelDiv.style.background = 'linear-gradient(90deg, #667eea 0%, #764ba2 100%)';\n",
              "            modelDiv.style.borderRadius = '5px';\n",
              "            modelDiv.style.textAlign = 'center';\n",
              "            modelDiv.style.fontWeight = 'bold';\n",
              "            modelDiv.innerHTML = 'Real-Time Air Drawing Digit Recognition';\n",
              "            div.appendChild(modelDiv);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            video.width = 640;\n",
              "            video.height = 480;\n",
              "            video.setAttribute('playsinline', '');\n",
              "            video.onclick = () => { shutdown = true; };\n",
              "            stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"user\"}});\n",
              "            div.appendChild(video);\n",
              "\n",
              "            labelDiv = document.createElement('div');\n",
              "            labelDiv.style.marginTop = '10px';\n",
              "            labelDiv.style.fontSize = '24px';\n",
              "            labelDiv.style.fontWeight = 'bold';\n",
              "            labelDiv.style.textAlign = 'center';\n",
              "            labelDiv.style.padding = '20px';\n",
              "            labelDiv.style.background = '#f0f0f0';\n",
              "            labelDiv.style.borderRadius = '5px';\n",
              "            labelDiv.innerHTML = 'Draw a digit in the air with your finger! ✍️';\n",
              "            div.appendChild(labelDiv);\n",
              "\n",
              "            imgElement = document.createElement('img');\n",
              "            imgElement.style.position = 'absolute';\n",
              "            imgElement.style.zIndex = 1;\n",
              "            imgElement.style.display = 'none';\n",
              "            div.appendChild(imgElement);\n",
              "\n",
              "            captureCanvas = document.createElement('canvas');\n",
              "            captureCanvas.width = 640;\n",
              "            captureCanvas.height = 480;\n",
              "\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "            return stream;\n",
              "        }\n",
              "        async function stream_frame(label, imgData) {\n",
              "            if (shutdown) {\n",
              "                removeDom();\n",
              "                shutdown = false;\n",
              "                return '';\n",
              "            }\n",
              "\n",
              "            var preCreate = Date.now();\n",
              "            stream = await createDom();\n",
              "\n",
              "            var preShow = Date.now();\n",
              "            if (label != \"\") {\n",
              "                labelDiv.innerHTML = label; // Removed JSON.parse()\n",
              "            }\n",
              "\n",
              "            if (imgData != \"\") {\n",
              "                var videoRect = video.getClientRects()[0];\n",
              "                imgElement.style.top = videoRect.top + \"px\";\n",
              "                imgElement.style.left = videoRect.left + \"px\";\n",
              "                imgElement.style.width = videoRect.width + \"px\";\n",
              "                imgElement.style.height = videoRect.height + \"px\";\n",
              "                imgElement.src = imgData; // Removed JSON.parse()\n",
              "            }\n",
              "\n",
              "            var preCapture = Date.now();\n",
              "            var result = await new Promise(function(resolve, reject) {\n",
              "                pendingResolve = resolve;\n",
              "            });\n",
              "            shutdown = false;\n",
              "\n",
              "            return {'create': preShow - preCreate,\n",
              "                    'show': preCapture - preShow,\n",
              "                    'capture': Date.now() - preCapture,\n",
              "                    'img': result};\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ea48fb0aa20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SESSION ENDED\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-learn tensorflow numpy matplotlib opencv-python mediapipe pillow\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from collections import deque\n",
        "import time\n",
        "from IPython.display import display, Javascript, HTML, clear_output\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import warnings\n",
        "import json # Import the json library\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Loading MNIST Dataset...\")\n",
        "mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
        "X, y = mnist.data, mnist.target\n",
        "X = np.array(X)\n",
        "y = np.array(y).astype(int)\n",
        "X = X / 255.0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42, stratify=y)\n",
        "print(\"✓ Dataset loaded!\")\n",
        "\n",
        "print(\"\\nTraining KNN Model...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
        "knn_model.fit(X_train[:10000], y_train[:10000])\n",
        "print(\"✓ KNN trained!\")\n",
        "\n",
        "print(\"\\nTraining SVM Model...\")\n",
        "svm_model = SVC(kernel='rbf', gamma='scale', C=10, random_state=42, probability=True)\n",
        "svm_model.fit(X_train[:10000], y_train[:10000])\n",
        "print(\"✓ SVM trained!\")\n",
        "\n",
        "print(\"\\nTraining ANN Model...\")\n",
        "y_train_ann = to_categorical(y_train, 10)\n",
        "ann_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "ann_model.fit(X_train, y_train_ann, epochs=10, batch_size=128, validation_split=0.1, verbose=0)\n",
        "print(\"✓ ANN trained!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL MODELS READY!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def video_stream():\n",
        "    js = Javascript('''\n",
        "        var video;\n",
        "        var div = null;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "        var imgElement;\n",
        "        var labelDiv;\n",
        "\n",
        "        var pendingResolve = null;\n",
        "        var shutdown = false;\n",
        "\n",
        "        function removeDom() {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "            video = null;\n",
        "            div = null;\n",
        "            stream = null;\n",
        "            imgElement = null;\n",
        "            captureCanvas = null;\n",
        "            labelDiv = null;\n",
        "        }\n",
        "\n",
        "        function onAnimationFrame() {\n",
        "            if (!shutdown) {\n",
        "                window.requestAnimationFrame(onAnimationFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "                var result = \"\";\n",
        "                if (!shutdown) {\n",
        "                    captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                    result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "                }\n",
        "                var lp = pendingResolve;\n",
        "                pendingResolve = null;\n",
        "                lp(result);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function createDom() {\n",
        "            if (div !== null) {\n",
        "                return stream;\n",
        "            }\n",
        "\n",
        "            div = document.createElement('div');\n",
        "            div.style.border = '2px solid black';\n",
        "            div.style.padding = '10px';\n",
        "            div.style.width = '660px';\n",
        "            div.style.margin = '20px auto';\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const modelDiv = document.createElement('div');\n",
        "            modelDiv.style.color = 'white';\n",
        "            modelDiv.style.fontSize = '18px';\n",
        "            modelDiv.style.padding = '10px';\n",
        "            modelDiv.style.marginBottom = '10px';\n",
        "            modelDiv.style.background = 'linear-gradient(90deg, #667eea 0%, #764ba2 100%)';\n",
        "            modelDiv.style.borderRadius = '5px';\n",
        "            modelDiv.style.textAlign = 'center';\n",
        "            modelDiv.style.fontWeight = 'bold';\n",
        "            modelDiv.innerHTML = 'Real-Time Air Drawing Digit Recognition';\n",
        "            div.appendChild(modelDiv);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.setAttribute('playsinline', '');\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"user\"}});\n",
        "            div.appendChild(video);\n",
        "\n",
        "            labelDiv = document.createElement('div');\n",
        "            labelDiv.style.marginTop = '10px';\n",
        "            labelDiv.style.fontSize = '24px';\n",
        "            labelDiv.style.fontWeight = 'bold';\n",
        "            labelDiv.style.textAlign = 'center';\n",
        "            labelDiv.style.padding = '20px';\n",
        "            labelDiv.style.background = '#f0f0f0';\n",
        "            labelDiv.style.borderRadius = '5px';\n",
        "            labelDiv.innerHTML = 'Draw a digit in the air with your finger! ✍️';\n",
        "            div.appendChild(labelDiv);\n",
        "\n",
        "            imgElement = document.createElement('img');\n",
        "            imgElement.style.position = 'absolute';\n",
        "            imgElement.style.zIndex = 1;\n",
        "            imgElement.style.display = 'none';\n",
        "            div.appendChild(imgElement);\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640;\n",
        "            captureCanvas.height = 480;\n",
        "\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "            return stream;\n",
        "        }\n",
        "        async function stream_frame(label, imgData) {\n",
        "            if (shutdown) {\n",
        "                removeDom();\n",
        "                shutdown = false;\n",
        "                return '';\n",
        "            }\n",
        "\n",
        "            var preCreate = Date.now();\n",
        "            stream = await createDom();\n",
        "\n",
        "            var preShow = Date.now();\n",
        "            if (label != \"\") {\n",
        "                labelDiv.innerHTML = label; // Removed JSON.parse()\n",
        "            }\n",
        "\n",
        "            if (imgData != \"\") {\n",
        "                var videoRect = video.getClientRects()[0];\n",
        "                imgElement.style.top = videoRect.top + \"px\";\n",
        "                imgElement.style.left = videoRect.left + \"px\";\n",
        "                imgElement.style.width = videoRect.width + \"px\";\n",
        "                imgElement.style.height = videoRect.height + \"px\";\n",
        "                imgElement.src = imgData; // Removed JSON.parse()\n",
        "            }\n",
        "\n",
        "            var preCapture = Date.now();\n",
        "            var result = await new Promise(function(resolve, reject) {\n",
        "                pendingResolve = resolve;\n",
        "            });\n",
        "            shutdown = false;\n",
        "\n",
        "            return {'create': preShow - preCreate,\n",
        "                    'show': preCapture - preShow,\n",
        "                    'capture': Date.now() - preCapture,\n",
        "                    'img': result};\n",
        "        }\n",
        "        ''')\n",
        "\n",
        "    display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "    # Encode label and bbox as JSON strings\n",
        "    data = eval_js('stream_frame({}, {})'.format(json.dumps(label), json.dumps(bbox)))\n",
        "    return data\n",
        "\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "drawing_canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
        "points = deque(maxlen=512)\n",
        "frame_count = 0\n",
        "last_prediction_time = time.time()\n",
        "current_prediction = {\"knn\": -1, \"svm\": -1, \"ann\": -1}\n",
        "confidence_scores = {\"knn\": 0, \"svm\": 0, \"ann\": 0}\n",
        "\n",
        "def preprocess_for_prediction(canvas):\n",
        "    gray = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        return None\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "\n",
        "    if w < 30 or h < 30:\n",
        "        return None\n",
        "\n",
        "    digit_roi = thresh[y:y+h, x:x+w]\n",
        "\n",
        "    size = max(w, h)\n",
        "    squared = np.zeros((size, size), dtype=np.uint8)\n",
        "    x_offset = (size - w) // 2\n",
        "    y_offset = (size - h) // 2\n",
        "    squared[y_offset:y_offset+h, x_offset:x_offset+w] = digit_roi\n",
        "\n",
        "    resized = cv2.resize(squared, (28, 28))\n",
        "    normalized = resized / 255.0\n",
        "    flattened = normalized.reshape(1, -1)\n",
        "\n",
        "    return flattened\n",
        "\n",
        "def predict_digit(processed_input):\n",
        "    if processed_input is None:\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    pred_knn = knn_model.predict(processed_input)[0]\n",
        "    pred_svm = svm_model.predict(processed_input)[0]\n",
        "    pred_ann = np.argmax(ann_model.predict(processed_input, verbose=0))\n",
        "\n",
        "    proba_knn = np.max(knn_model.predict_proba(processed_input))\n",
        "    proba_svm = np.max(svm_model.predict_proba(processed_input))\n",
        "    proba_ann = np.max(ann_model.predict(processed_input, verbose=0))\n",
        "\n",
        "    return pred_knn, pred_svm, pred_ann, proba_knn, proba_svm, proba_ann\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING REAL-TIME RECOGNITION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nInstructions:\")\n",
        "print(\"1. Show your index finger to the camera\")\n",
        "print(\"2. Draw digits (0-9) in the air\")\n",
        "print(\"3. Keep your finger visible while drawing\")\n",
        "print(\"4. Press 'C' to clear the canvas\")\n",
        "print(\"5. Click on video to stop\")\n",
        "print(\"\\nReady! Starting camera...\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "video_stream() # Call video_stream before the loop\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        js_reply = video_frame('', '')\n",
        "        if not js_reply:\n",
        "            break\n",
        "\n",
        "        frame = js_to_image(js_reply[\"img\"])\n",
        "        if frame is None:\n",
        "            break\n",
        "\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        result = hands.process(rgb_frame)\n",
        "\n",
        "        if result.multi_hand_landmarks:\n",
        "            for hand_landmarks in result.multi_hand_landmarks:\n",
        "                index_finger_tip = hand_landmarks.landmark[8]\n",
        "                h, w, c = frame.shape\n",
        "                cx, cy = int(index_finger_tip.x * w), int(index_finger_tip.y * h)\n",
        "\n",
        "                points.appendleft((cx, cy))\n",
        "                cv2.circle(frame, (cx, cy), 10, (0, 255, 0), -1)\n",
        "\n",
        "        for i in range(1, len(points)):\n",
        "            if points[i - 1] is None or points[i] is None:\n",
        "                continue\n",
        "            cv2.line(drawing_canvas, points[i - 1], points[i], (255, 255, 255), 8)\n",
        "            cv2.line(frame, points[i - 1], points[i], (0, 0, 255), 3)\n",
        "\n",
        "        frame_count += 1\n",
        "        current_time = time.time()\n",
        "\n",
        "        if frame_count % 15 == 0 and (current_time - last_prediction_time) > 0.5:\n",
        "            processed = preprocess_for_prediction(drawing_canvas)\n",
        "            if processed is not None:\n",
        "                pred_knn, pred_svm, pred_ann, conf_knn, conf_svm, conf_ann = predict_digit(processed)\n",
        "\n",
        "                if pred_knn is not None:\n",
        "                    current_prediction = {\"knn\": pred_knn, \"svm\": pred_svm, \"ann\": pred_ann}\n",
        "                    confidence_scores = {\"knn\": conf_knn, \"svm\": conf_svm, \"ann\": conf_ann}\n",
        "                    last_prediction_time = current_time\n",
        "\n",
        "        cv2.putText(frame, 'Press C to Clear', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        label_html = '<div style=\"display: flex; justify-content: space-around; margin-top: 10px;\">'\n",
        "\n",
        "        if current_prediction[\"knn\"] != -1:\n",
        "            label_html += f'''\n",
        "            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 15px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
        "                <div style=\"color: white; font-size: 16px; margin-bottom: 5px;\">KNN</div>\n",
        "                <div style=\"color: white; font-size: 48px; font-weight: bold;\">{current_prediction[\"knn\"]}</div>\n",
        "                <div style=\"color: white; font-size: 14px;\">{confidence_scores[\"knn\"]*100:.1f}%</div>\n",
        "            </div>\n",
        "            '''\n",
        "\n",
        "            label_html += f'''\n",
        "            <div style=\"background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 15px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
        "                <div style=\"color: white; font-size: 16px; margin-bottom: 5px;\">SVM</div>\n",
        "                <div style=\"color: white; font-size: 48px; font-weight: bold;\">{current_prediction[\"svm\"]}</div>\n",
        "                <div style=\"color: white; font-size: 14px;\">{confidence_scores[\"svm\"]*100:.1f}%</div>\n",
        "            </div>\n",
        "            '''\n",
        "\n",
        "            label_html += f'''\n",
        "            <div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); padding: 15px; border-radius: 10px; min-width: 150px; text-align: center;\">\n",
        "                <div style=\"color: white; font-size: 16px; margin-bottom: 5px;\">ANN</div>\n",
        "                <div style=\"color: white; font-size: 48px; font-weight: bold;\">{current_prediction[\"ann\"]}</div>\n",
        "                <div style=\"color: white; font-size: 14px;\">{confidence_scores[\"ann\"]*100:.1f}%</div>\n",
        "            </div>\n",
        "            '''\n",
        "        else:\n",
        "            label_html += '<div style=\"color: #666; font-size: 18px;\">Draw a digit in the air! ✍️</div>'\n",
        "\n",
        "        label_html += '</div>'\n",
        "\n",
        "        _, buffer = cv2.imencode('.jpg', frame)\n",
        "        img_str = b64encode(buffer).decode('utf-8')\n",
        "        img_data = f'data:image/jpeg;base64,{img_str}'\n",
        "\n",
        "        js_reply = video_frame(label_html, img_data)\n",
        "\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == ord('c') or key == ord('C'):\n",
        "            drawing_canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
        "            points.clear()\n",
        "            current_prediction = {\"knn\": -1, \"svm\": -1, \"ann\": -1}\n",
        "            confidence_scores = {\"knn\": 0, \"svm\": 0, \"ann\": 0}\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "finally:\n",
        "    hands.close()\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SESSION ENDED\")\n",
        "    print(\"=\"*70)"
      ]
    }
  ]
}